"""
å¯¹è¯å¼ QAï¼šStreamlit + LangGraphï¼ˆretrieve -> generateï¼‰ï¼Œå¤šè½®æé—®ã€‚
ä½¿ç”¨å‰è¯·å…ˆè¿è¡Œ build_db.py <æ–‡æ¡£ç›®å½•> æ„å»ºå‘é‡åº“ï¼Œå¹¶ç¡®ä¿ dev ä¸‹ pgvector å·²å¯åŠ¨ã€‚
ç¯å¢ƒå˜é‡ç”± uv ç­‰è¿è¡Œæ—¶æ³¨å…¥ã€‚
"""
import streamlit as st
from graph import build_qa_graph, QAState


@st.cache_resource
def get_graph():
    return build_qa_graph()


def main():
    st.set_page_config(page_title="æ–‡æ¡£ QA", page_icon="ğŸ“š")
    st.title("ğŸ“š æ–‡æ¡£ QAï¼ˆLangGraph + PGVectorï¼‰")
    st.caption("åŸºäºæœ¬åœ° Markdown æ–‡æ¡£çš„æ£€ç´¢ä¸å¯¹è¯å¼é—®ç­”")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for q, a in st.session_state.chat_history:
        with st.chat_message("user"):
            st.markdown(q)
        with st.chat_message("assistant"):
            st.markdown(a)

    if prompt := st.chat_input("è¾“å…¥é—®é¢˜..."):
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("æ£€ç´¢å¹¶ç”Ÿæˆå›ç­”â€¦"):
                graph = get_graph()
                result = graph.invoke(
                    QAState(
                        question=prompt,
                        chat_history=st.session_state.chat_history,
                        retrieved_docs=[],
                        answer="",
                    )
                )
            st.markdown(result["answer"])

        st.session_state.chat_history.append((prompt, result["answer"]))
        st.rerun()


if __name__ == "__main__":
    main()
